# ğŸ©º MediBot â€“ Medical Diagnosis Chatbots

![Made with Python](https://img.shields.io/badge/Made%20with-Python-3776AB?style=for-the-badge&logo=python&logoColor=white)
![Frontend: HTML/CSS](https://img.shields.io/badge/Frontend-HTML%2FCSS-blue?style=for-the-badge)
![MIT License](https://img.shields.io/badge/License-MIT-yellow.svg?style=for-the-badge)
![Status](https://img.shields.io/badge/Status-Active-brightgreen?style=for-the-badge)

An advanced chatbot for preliminary medical diagnosis using open source **Mistral LLM**, **LangChain**, and **PineconeDB**. It supports:
- Symptom-based queries  
- Analysis of user-inputted test results  
- Probability-based disease predictions

The backend is built using **Flask**, ensuring lightweight and responsive deployment.

---

## ğŸš€ Features

- ğŸ” Retrieval-Augmented Generation (RAG) powered by **open-source Mistral LLM**
- âš•ï¸ Ingests and embeds medical knowledge from the Gale Encyclopedia of Medicine using **Hugging Face** models
- ğŸ“¦ Stores vector embeddings in **Pinecone** for fast similarity-based retrieval
- ğŸ§  Context-aware responses generated by combining the user query with relevant medical context
- ğŸŒ Simple and clean frontend built with **HTML/CSS**
- ğŸ³ Fully containerized using **Docker**
- ğŸ” CI/CD pipeline integrated for automatic deployment and testing

---

## ğŸ§± Tech Stack

| Layer          | Tools/Frameworks Used                                     |
|----------------|-----------------------------------------------------------|
| **Frontend**   | HTML, CSS                                                 |
| **Backend**    | Python, Flask                                             |
| **RAG Engine** | LangChain, Pinecone, Mistral LLM (via Hugging Face)       |
| **Vector DB**  | Pinecone (FAISS alternative for production)               |
| **Container**  | Docker                                                    |
| **Deployment** | CI/CD pipeline                                            |

---

## ğŸ› ï¸ How It Works

1. ğŸ“˜ **Embedding Medical Data**  
   - Medical content is embedded into vector representations using Hugging Face transformers.
   - These embeddings are stored in Pinecone for fast retrieval.

2. ğŸ” **Query Processing**  
   - A user submits a symptom or medical test-related query.
   - LangChain fetches relevant context using vector similarity from Pinecone.

3. ğŸ§¾ **LLM-Based Answering**  
   - Mistral LLM uses retrieved documents and user input to generate medically coherent answers.

4. ğŸ” **Session Handling**  
   - Conversations are state-aware using LangChain's memory components.

---


## ğŸ“„ License
This project is licensed under the MIT License.

---


## ğŸ“ Author
Kreesh Modi | IIT Kharagpur Mechanical Engineering

Email: [kreeshmodi2018@gmail.com]
